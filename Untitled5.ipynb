{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cPickle as pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import theano\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import lasagne\n",
    "from lasagne import layers\n",
    "from lasagne.updates import nesterov_momentum\n",
    "from nolearn.lasagne import NeuralNet\n",
    "from nolearn.lasagne import visualize\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "def float32(k):\n",
    "    return np.cast['float32'](k)\n",
    "\n",
    "class PlotLosses(object):\n",
    "    def __init__(self, figsize=(8, 6)):\n",
    "        plt.plot([],[])\n",
    "    def __call__(self, nn, train_history):\n",
    "        train_loss=np.array([i[\"train_loss\"] for i in nn.train_history_])\n",
    "        valid_loss=np.array([i[\"valid_loss\"] for i in nn.train_history_])\n",
    "        \n",
    "        plt.gca().cla()\n",
    "        plt.plot(train_loss, label=\"train\")\n",
    "        plt.plot(valid_loss, label=\"test\")\n",
    "        \n",
    "        plt.legend()\n",
    "        plt.draw()\n",
    "\n",
    "class AdjustVariable(object):\n",
    "    def __init__(self, name, start=0.03, stop=0.001):\n",
    "        self.name=name\n",
    "        self.start, self.stop=start, stop\n",
    "        self.ls=None\n",
    "    def __call__(self, nn, train_history):\n",
    "        if self.ls is None:\n",
    "            self.ls=np.linspace(self.start, self.stop, nn.max_epochs)\n",
    "        epoch=train_history[-1]['epoch']\n",
    "        new_value=float32(self.ls[epoch-1])\n",
    "        getattr(nn, self.name).set_value(new_value)\n",
    "\n",
    "def load_data(path):\n",
    "    x_train = np.zeros((50000, 3, 32, 32), dtype='uint8')\n",
    "    y_train = np.zeros((50000,), dtype=\"uint8\")\n",
    "\n",
    "    for i in range(1, 6):\n",
    "        data = unpickle(os.path.join(path, 'data_batch_' + str(i)))\n",
    "        images = data['data'].reshape(10000, 3, 32, 32)\n",
    "        labels = data['labels']\n",
    "        x_train[(i - 1) * 10000:i * 10000, :, :, :] = images\n",
    "        y_train[(i - 1) * 10000:i * 10000] = labels\n",
    "\n",
    "    test_data = unpickle(os.path.join(path, 'test_batch'))\n",
    "    x_test = test_data['data'].reshape(10000, 3, 32, 32)\n",
    "    y_test = np.array(test_data['labels'])\n",
    "\n",
    "    return x_train/float32(255), y_train, x_test/float32(255), y_test\n",
    "\n",
    "\n",
    "def unpickle(file):\n",
    "    f = open(file, 'rb')\n",
    "    dict = pickle.load(f)\n",
    "    f.close()\n",
    "    return dict\n",
    "\n",
    "\n",
    "net = NeuralNet(\n",
    "    layers=[('input', layers.InputLayer),\n",
    "            ('conv2d1', layers.Conv2DLayer),\n",
    "            ('maxpool1', layers.MaxPool2DLayer),\n",
    "            ('conv2d2', layers.Conv2DLayer),\n",
    "            ('maxpool2', layers.MaxPool2DLayer),\n",
    "            ('dense1', layers.DenseLayer),\n",
    "            ('drop1', layers.DropoutLayer),\n",
    "            ('dense2', layers.DenseLayer),\n",
    "            ('drop2', layers.DropoutLayer),\n",
    "            ('output', layers.DenseLayer),\n",
    "            ],\n",
    "    input_shape=(None, 3, 32, 32),\n",
    "\n",
    "    conv2d1_num_filters=32,\n",
    "    conv2d1_filter_size=(5, 5),\n",
    "    conv2d1_nonlinearity=lasagne.nonlinearities.rectify,\n",
    "    \n",
    "\n",
    "    maxpool1_pool_size=(2, 2),\n",
    "\n",
    "    conv2d2_num_filters=32,\n",
    "    conv2d2_filter_size=(5, 5),\n",
    "    conv2d2_nonlinearity=lasagne.nonlinearities.rectify,\n",
    "\n",
    "    maxpool2_pool_size=(2, 2),\n",
    "\n",
    "    dense1_num_units=256,\n",
    "    dense1_nonlinearity=lasagne.nonlinearities.rectify,\n",
    "    \n",
    "    drop1_p=0.5,\n",
    "\n",
    "    dense2_num_units=256,\n",
    "    \n",
    "    dense2_nonlinearity=lasagne.nonlinearities.rectify,\n",
    "    update_learning_rate=theano.shared(float32(0.03)),\n",
    "    update_momentum=theano.shared(float32(0.9)),\n",
    "    \n",
    "    drop2_p=0.5,\n",
    "\n",
    "    output_nonlinearity=lasagne.nonlinearities.softmax,\n",
    "    output_num_units=10,\n",
    "    \n",
    "    update=nesterov_momentum,\n",
    "    on_epoch_finished=[AdjustVariable('update_learning_rate',\n",
    "                                      start=0.03, \n",
    "                                      stop=0.0001), \n",
    "                       AdjustVariable('update_momentum',\n",
    "                                      start=0.9,\n",
    "                                      stop=0.999),\n",
    "                      PlotLosses(figsize=(8, 6))],\n",
    "    \n",
    "    max_epochs=100,\n",
    "    verbose=True,\n",
    "    \n",
    ")\n",
    "\n",
    "net2 = NeuralNet(\n",
    "    layers=[('input', layers.InputLayer),\n",
    "            ('conv2d1', layers.Conv2DLayer),\n",
    "            ('maxpool1', layers.MaxPool2DLayer),\n",
    "            ('conv2d2', layers.Conv2DLayer),\n",
    "            ('maxpool2', layers.MaxPool2DLayer),\n",
    "            ('dense1', layers.DenseLayer),\n",
    "            ('drop1', layers.DropoutLayer),\n",
    "            ('dense2', layers.DenseLayer),\n",
    "            ('drop2', layers.DropoutLayer),\n",
    "            ('output', layers.DenseLayer),\n",
    "            ],\n",
    "    input_shape=(None, 3, 32, 32),\n",
    "\n",
    "    conv2d1_num_filters=32,\n",
    "    conv2d1_filter_size=(3, 3),\n",
    "    conv2d1_nonlinearity=lasagne.nonlinearities.rectify,\n",
    "    conv2d1_W=lasagne.init.GlorotUniform(),\n",
    "\n",
    "    \n",
    "\n",
    "    maxpool1_pool_size=(2, 2),\n",
    "\n",
    "    conv2d2_num_filters=32,\n",
    "    conv2d2_filter_size=(4, 4),\n",
    "    conv2d2_nonlinearity=lasagne.nonlinearities.rectify,\n",
    "    conv2d2_W=lasagne.init.GlorotUniform(),\n",
    "\n",
    "    maxpool2_pool_size=(2, 2),\n",
    "\n",
    "    dense1_num_units=256,\n",
    "    dense1_nonlinearity=lasagne.nonlinearities.rectify,\n",
    "    \n",
    "    drop1_p=0.5,\n",
    "\n",
    "    dense2_num_units=256,\n",
    "    \n",
    "    dense2_nonlinearity=lasagne.nonlinearities.rectify,\n",
    "    update_learning_rate=theano.shared(float32(0.03)),\n",
    "    update_momentum=theano.shared(float32(0.9)),\n",
    "    \n",
    "    drop2_p=0.5,\n",
    "\n",
    "    output_nonlinearity=lasagne.nonlinearities.softmax,\n",
    "    output_num_units=10,\n",
    "    \n",
    "    update=nesterov_momentum,\n",
    "    on_epoch_finished=[AdjustVariable('update_learning_rate',\n",
    "                                      start=0.03, \n",
    "                                      stop=0.0001), \n",
    "                       AdjustVariable('update_momentum',\n",
    "                                      start=0.9,\n",
    "                                      stop=0.999),\n",
    "                      PlotLosses(figsize=(8, 6))],\n",
    "    \n",
    "    max_epochs=100,\n",
    "    verbose=True,\n",
    "    \n",
    ")\n",
    "\n",
    "net3 = NeuralNet(\n",
    "    layers=[('input', layers.InputLayer),\n",
    "            ('conv2d1', layers.Conv2DLayer),\n",
    "            ('maxpool1', layers.MaxPool2DLayer),\n",
    "            ('conv2d2', layers.Conv2DLayer),\n",
    "            ('maxpool2', layers.MaxPool2DLayer),\n",
    "            ('conv2d3', layers.Conv2DLayer),\n",
    "            ('maxpool3', layers.MaxPool2DLayer),           \n",
    "            ('dense1', layers.DenseLayer),\n",
    "            ('drop1', layers.DropoutLayer),\n",
    "            ('dense2', layers.DenseLayer),\n",
    "            ('drop2', layers.DropoutLayer),\n",
    "            ('output', layers.DenseLayer),\n",
    "            ],\n",
    "    input_shape=(None, 3, 32, 32),\n",
    "\n",
    "    conv2d1_num_filters=32,\n",
    "    conv2d1_filter_size=(3, 3),\n",
    "    conv2d1_nonlinearity=lasagne.nonlinearities.rectify,\n",
    "    conv2d1_W=lasagne.init.GlorotUniform(),\n",
    "\n",
    "    \n",
    "\n",
    "    maxpool1_pool_size=(2, 2),\n",
    "\n",
    "    conv2d2_num_filters=32,\n",
    "    conv2d2_filter_size=(2, 2),\n",
    "    conv2d2_nonlinearity=lasagne.nonlinearities.rectify,\n",
    "    conv2d2_W=lasagne.init.GlorotUniform(),\n",
    "\n",
    "    maxpool2_pool_size=(2, 2),\n",
    "\n",
    "    conv2d3_num_filters=32,\n",
    "    conv2d3_filter_size=(2, 2),\n",
    "    conv2d3_nonlinearity=lasagne.nonlinearities.rectify,\n",
    "    conv2d3_W=lasagne.init.GlorotUniform(),\n",
    "\n",
    "    maxpool3_pool_size=(2, 2),\n",
    "\n",
    "    dense1_num_units=256,\n",
    "    dense1_nonlinearity=lasagne.nonlinearities.rectify,\n",
    "    \n",
    "    drop1_p=0.5,\n",
    "\n",
    "    dense2_num_units=256,\n",
    "    \n",
    "    dense2_nonlinearity=lasagne.nonlinearities.rectify,\n",
    "    update_learning_rate=theano.shared(float32(0.03)),\n",
    "    update_momentum=theano.shared(float32(0.9)),\n",
    "    \n",
    "    drop2_p=0.5,\n",
    "\n",
    "    output_nonlinearity=lasagne.nonlinearities.softmax,\n",
    "    output_num_units=10,\n",
    "    \n",
    "    update=nesterov_momentum,\n",
    "    on_epoch_finished=[AdjustVariable('update_learning_rate',\n",
    "                                      start=0.03, \n",
    "                                      stop=0.0001), \n",
    "                       AdjustVariable('update_momentum',\n",
    "                                      start=0.9,\n",
    "                                      stop=0.999),\n",
    "                      PlotLosses(figsize=(8, 6))],\n",
    "    \n",
    "    max_epochs=100,\n",
    "    verbose=True,\n",
    "    \n",
    ")\n",
    "\n",
    "net4 = NeuralNet(\n",
    "    layers=[('input', layers.InputLayer),\n",
    "            ('conv2d1', layers.Conv2DLayer),\n",
    "            ('maxpool1', layers.MaxPool2DLayer),\n",
    "            ('conv2d2', layers.Conv2DLayer),\n",
    "            ('maxpool2', layers.MaxPool2DLayer),\n",
    "            ('conv2d3', layers.Conv2DLayer),\n",
    "            ('maxpool3', layers.MaxPool2DLayer),           \n",
    "            ('dense1', layers.DenseLayer),\n",
    "            ('drop1', layers.DropoutLayer),\n",
    "            ('dense2', layers.DenseLayer),\n",
    "            ('drop2', layers.DropoutLayer),\n",
    "            ('output', layers.DenseLayer),\n",
    "            ],\n",
    "    input_shape=(None, 3, 32, 32),\n",
    "\n",
    "    conv2d1_num_filters=20,\n",
    "    conv2d1_filter_size=(3, 3),\n",
    "    conv2d1_nonlinearity=lasagne.nonlinearities.rectify,\n",
    "    conv2d1_W=lasagne.init.GlorotUniform(),\n",
    "\n",
    "    \n",
    "\n",
    "    maxpool1_pool_size=(2, 2),\n",
    "\n",
    "    conv2d2_num_filters=32,\n",
    "    conv2d2_filter_size=(2, 2),\n",
    "    conv2d2_nonlinearity=lasagne.nonlinearities.rectify,\n",
    "    conv2d2_W=lasagne.init.GlorotUniform(),\n",
    "\n",
    "    maxpool2_pool_size=(2, 2),\n",
    "\n",
    "    conv2d3_num_filters=64,\n",
    "    conv2d3_filter_size=(2, 2),\n",
    "    conv2d3_nonlinearity=lasagne.nonlinearities.rectify,\n",
    "    conv2d3_W=lasagne.init.GlorotUniform(),\n",
    "\n",
    "    maxpool3_pool_size=(2, 2),\n",
    "\n",
    "    dense1_num_units=500,\n",
    "    dense1_nonlinearity=lasagne.nonlinearities.rectify,\n",
    "    \n",
    "    drop1_p=0.5,\n",
    "\n",
    "    dense2_num_units=500,\n",
    "    \n",
    "    dense2_nonlinearity=lasagne.nonlinearities.rectify,\n",
    "    update_learning_rate=theano.shared(float32(0.03)),\n",
    "    update_momentum=theano.shared(float32(0.9)),\n",
    "    \n",
    "    drop2_p=0.5,\n",
    "\n",
    "    output_nonlinearity=lasagne.nonlinearities.softmax,\n",
    "    output_num_units=10,\n",
    "    \n",
    "    update=nesterov_momentum,\n",
    "    on_epoch_finished=[AdjustVariable('update_learning_rate',\n",
    "                                      start=0.03, \n",
    "                                      stop=0.0001), \n",
    "                       AdjustVariable('update_momentum',\n",
    "                                      start=0.9,\n",
    "                                      stop=0.999),\n",
    "                      PlotLosses(figsize=(8, 6))],\n",
    "    \n",
    "    max_epochs=100,\n",
    "    verbose=True,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce 820M (CNMeM is disabled)\n"
     ]
    }
   ],
   "source": [
    "import cPickle as pickle\n",
    "import os\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import lasagne\n",
    "from lasagne import layers\n",
    "from lasagne.updates import nesterov_momentum\n",
    "from nolearn.lasagne import NeuralNet\n",
    "from nolearn.lasagne import visualize\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load Functions\n",
    "def float32(k):\n",
    "    return np.cast['float32'](k)\n",
    "\n",
    "class PlotLosses(object):\n",
    "    def __init__(self, figsize=(8, 6)):\n",
    "        plt.plot([],[])\n",
    "    def __call__(self, nn, train_history):\n",
    "        train_loss=np.array([i[\"train_loss\"] for i in nn.train_history_])\n",
    "        valid_loss=np.array([i[\"valid_loss\"] for i in nn.train_history_])\n",
    "        \n",
    "        plt.gca().cla()\n",
    "        plt.plot(train_loss, label=\"train\")\n",
    "        plt.plot(valid_loss, label=\"test\")\n",
    "        \n",
    "        plt.legend()\n",
    "        plt.draw()\n",
    "\n",
    "class AdjustVariable(object):\n",
    "    def __init__(self, name, start=0.03, stop=0.001):\n",
    "        self.name=name\n",
    "        self.start, self.stop=start, stop\n",
    "        self.ls=None\n",
    "    def __call__(self, nn, train_history):\n",
    "        if self.ls is None:\n",
    "            self.ls=np.linspace(self.start, self.stop, nn.max_epochs)\n",
    "        epoch=train_history[-1]['epoch']\n",
    "        new_value=float32(self.ls[epoch-1])\n",
    "        getattr(nn, self.name).set_value(new_value)\n",
    "\n",
    "def load_data(path):\n",
    "    x_train = np.zeros((50000, 3, 32, 32), dtype='uint8')\n",
    "    y_train = np.zeros((50000,), dtype=\"uint8\")\n",
    "\n",
    "    for i in range(1, 6):\n",
    "        data = unpickle(os.path.join(path, 'data_batch_' + str(i)))\n",
    "        images = data['data'].reshape(10000, 3, 32, 32)\n",
    "        labels = data['labels']\n",
    "        x_train[(i - 1) * 10000:i * 10000, :, :, :] = images\n",
    "        y_train[(i - 1) * 10000:i * 10000] = labels\n",
    "\n",
    "    test_data = unpickle(os.path.join(path, 'test_batch'))\n",
    "    x_test = test_data['data'].reshape(10000, 3, 32, 32)\n",
    "    y_test = np.array(test_data['labels'])\n",
    "\n",
    "    return x_train/float32(255), y_train, x_test/float32(255), y_test\n",
    "\n",
    "def load_data2(path):\n",
    "    x_train = np.zeros((50000, 3, 32, 32), dtype='uint8')\n",
    "    y_train = np.zeros((50000,), dtype=\"uint8\")\n",
    "\n",
    "    for i in range(1, 6):\n",
    "        data = unpickle(os.path.join(path, 'data_batch_' + str(i)))\n",
    "        images = data['data'].reshape(10000, 3, 32, 32)\n",
    "        labels = data['labels']\n",
    "        x_train[(i - 1) * 10000:i * 10000, :, :, :] = images\n",
    "        y_train[(i - 1) * 10000:i * 10000] = labels\n",
    "\n",
    "    test_data = unpickle(os.path.join(path, 'test_batch'))\n",
    "    x_test = test_data['data'].reshape(10000, 3, 32, 32)\n",
    "    y_test = np.array(test_data['labels'])\n",
    "\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "\n",
    "def unpickle(file):\n",
    "    f = open(file, 'rb')\n",
    "    dict = pickle.load(f)\n",
    "    f.close()\n",
    "    return dict\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "def displayImage(image, predict, actual):\n",
    "    img=np.ascontiguousarray(image.transpose(1,2,0))\n",
    "    img = Image.fromarray(img, 'RGB')\n",
    "    plt.title(\"Predicted Label: \"+predict+ \"\\nActual Label: \" +actual)\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    \n",
    "def loadModel(modelName):\n",
    "    fileName=file(modelName, 'rb')\n",
    "    loadedModel=pickle.load(fileName)\n",
    "    fileName.close()\n",
    "    return loadedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = load_data(os.path.expanduser('F:/pandas-ex/mnist-test/cifar-10-batches-py'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'net' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-2a3fb7145f39>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnetwork\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'net' is not defined"
     ]
    }
   ],
   "source": [
    "network=net.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net = NeuralNet(\n",
    "    layers=[('input', layers.InputLayer),\n",
    "            ('conv2d1', layers.Conv2DLayer),\n",
    "            ('maxpool1', layers.MaxPool2DLayer),\n",
    "            ('conv2d2', layers.Conv2DLayer),\n",
    "            ('maxpool2', layers.MaxPool2DLayer),\n",
    "            ('conv2d3', layers.Conv2DLayer),\n",
    "            ('maxpool3', layers.MaxPool2DLayer),\n",
    "            ('output', layers.DenseLayer),\n",
    "            ],\n",
    "    input_shape=(None, 3, 32, 32),\n",
    "\n",
    "    conv2d1_num_filters=16,\n",
    "    conv2d1_filter_size=(5, 5),\n",
    "    conv2d1_nonlinearity=lasagne.nonlinearities.rectify,\n",
    "    conv2d1_stride=(1, 1), conv2d1_pad=(2, 2),\n",
    "\n",
    "    maxpool1_pool_size=(2, 2), maxpool1_stride=(2, 2),\n",
    "\n",
    "    conv2d2_num_filters=20,\n",
    "    conv2d2_filter_size=(5, 5),\n",
    "    conv2d2_stride=(1, 1),\n",
    "    conv2d2_pad=(2, 2),\n",
    "    conv2d2_nonlinearity=lasagne.nonlinearities.rectify,\n",
    "\n",
    "    maxpool2_pool_size=(2, 2),\n",
    "\n",
    "    conv2d3_num_filters=20,\n",
    "    conv2d3_filter_size=(5, 5),\n",
    "    conv2d3_stride=(1, 1),\n",
    "    conv2d3_pad=(2, 2),\n",
    "    conv2d3_nonlinearity=lasagne.nonlinearities.rectify,\n",
    "    \n",
    "    maxpool3_pool_size=(2, 2), maxpool3_stride=(2, 2),\n",
    "\n",
    "    output_nonlinearity=lasagne.nonlinearities.softmax,\n",
    "    output_num_units=10,\n",
    "\n",
    "    update=nesterov_momentum,\n",
    "    update_momentum=0.9,\n",
    "    update_learning_rate=0.01,\n",
    "    on_epoch_finished=[AdjustVariable('update_learning_rate',\n",
    "                                      start=0.03, \n",
    "                                      stop=0.0001), \n",
    "                       AdjustVariable('update_momentum',\n",
    "                                      start=0.9,\n",
    "                                      stop=0.999)],\n",
    "    max_epochs=100,\n",
    "    verbose=True,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Neural Network with 22466 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name      size\n",
      "---  --------  --------\n",
      "  0  input     3x32x32\n",
      "  1  conv2d1   16x32x32\n",
      "  2  maxpool1  16x16x16\n",
      "  3  conv2d2   20x16x16\n",
      "  4  maxpool2  20x8x8\n",
      "  5  conv2d3   20x8x8\n",
      "  6  maxpool3  20x4x4\n",
      "  7  output    10\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'set_value'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-2a3fb7145f39>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnetwork\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mf:\\pandas-ex\\nolearn-test\\nolearn\\lasagne\\base.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, epochs)\u001b[0m\n\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 460\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    461\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    462\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\pandas-ex\\nolearn-test\\nolearn\\lasagne\\base.pyc\u001b[0m in \u001b[0;36mtrain_loop\u001b[1;34m(self, X, y, epochs)\u001b[0m\n\u001b[0;32m    554\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mon_epoch_finished\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 556\u001b[1;33m                     \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_history_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    557\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    558\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-bf762acf4d82>\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, nn, train_history)\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mepoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_history\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'epoch'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mnew_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mls\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'float' object has no attribute 'set_value'"
     ]
    }
   ],
   "source": [
    "network=net.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
